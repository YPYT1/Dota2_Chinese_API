"""
Dota2 API æ–‡æ¡£æ‰¹é‡ç¿»è¯‘è„šæœ¬
- æ”¯æŒæ— äººå€¼å®ˆé•¿æ—¶é—´è¿è¡Œ
- æ–­ç‚¹ç»­ä¼ 
- è‡ªåŠ¨ä¿å­˜è¿›åº¦
- ç¿»è¯‘åæ–‡ä»¶ä¿å­˜ä¸º xxx_cn.json
- è¯¦ç»†æ—¥å¿—è¾“å‡º + æ—¥å¿—æ–‡ä»¶
- æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œç¿»è¯‘ä¸åŒç›®å½•
"""
import json
import os
import sys
import time
import random
import logging
import threading
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ å½“å‰ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(__file__))
from smart_api_pool import SmartAPIPool

# ==================== æ—¥å¿—é…ç½® ====================

LOG_FILE = Path(__file__).parent.parent / "translate.log"

# åˆ›å»º logger
logger = logging.getLogger("translate")
logger.setLevel(logging.INFO)

# æ–‡ä»¶å¤„ç†å™¨ï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰
file_handler = logging.FileHandler(LOG_FILE, encoding='utf-8')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(logging.Formatter(
    '%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
))

# æ§åˆ¶å°å¤„ç†å™¨ï¼ˆç®€æ´è¾“å‡ºï¼‰
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter(
    '%(asctime)s | %(message)s',
    datefmt='%H:%M:%S'
))

logger.addHandler(file_handler)
logger.addHandler(console_handler)


def log(msg, level="info", worker_id=None):
    """ç»Ÿä¸€æ—¥å¿—è¾“å‡ºï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    # æ·»åŠ  worker æ ‡è¯†
    if worker_id is not None:
        msg = f"[W{worker_id}] {msg}"
    
    with log_lock:
        if level == "debug":
            logger.debug(msg)
        elif level == "warning":
            logger.warning(msg)
        elif level == "error":
            logger.error(msg)
        else:
            logger.info(msg)

# ==================== é…ç½® ====================

# æ•°æ®ç›®å½•
DATA_DIR = Path(__file__).parent.parent / "data"

# ç¿»è¯‘ä»»åŠ¡é…ç½®
TRANSLATE_TASKS = [
    {
        "source": "gameevents/events.json",
        "output": "gameevents/events_cn.json",
        "type": "game_event",
        "item_key": "items"
    },
    {
        "source": "luaapi/classes.json",
        "output": "luaapi/classes_cn.json",
        "type": "class",
        "item_key": "items"
    },
    {
        "source": "luaapi/functions.json",
        "output": "luaapi/functions_cn.json",
        "type": "function",
        "item_key": "items"
    },
    {
        "source": "luaapi/enums.json",
        "output": "luaapi/enums_cn.json",
        "type": "enum",
        "item_key": "items"
    },
    {
        "source": "luaapi/constants.json",
        "output": "luaapi/constants_cn.json",
        "type": "constant",
        "item_key": "items"
    },
    {
        "source": "panoramaapi/enums.json",
        "output": "panoramaapi/enums_cn.json",
        "type": "panorama_enum",
        "item_key": "items"
    },
    {
        "source": "panoramaevents/events.json",
        "output": "panoramaevents/events_cn.json",
        "type": "panorama_event",
        "item_key": "items"
    },
]

# è¿›åº¦æ–‡ä»¶
PROGRESS_FILE = Path(__file__).parent.parent / "translate_progress.json"

# å¤±è´¥è®°å½•æ–‡ä»¶
FAILED_FILE = Path(__file__).parent.parent / "translate_failed.json"

# ç¿»è¯‘æ¨¡å‹
MODEL = "deepseek-ai/DeepSeek-V3"

# çº¿ç¨‹é”ï¼ˆç”¨äºä¿æŠ¤å…±äº«èµ„æºï¼‰
progress_lock = threading.Lock()
failed_lock = threading.Lock()
log_lock = threading.Lock()

# ä»»åŠ¡åˆ†ç»„ï¼ˆç”¨äºå¹¶è¡Œç¿»è¯‘ï¼‰
TASK_GROUPS = [
    # ç»„1: gameevents
    [{"source": "gameevents/events.json", "output": "gameevents/events_cn.json", "type": "game_event", "item_key": "items"}],
    # ç»„2: luaapi (classes + functions)
    [
        {"source": "luaapi/classes.json", "output": "luaapi/classes_cn.json", "type": "class", "item_key": "items"},
        {"source": "luaapi/functions.json", "output": "luaapi/functions_cn.json", "type": "function", "item_key": "items"},
    ],
    # ç»„3: luaapi (enums + constants)
    [
        {"source": "luaapi/enums.json", "output": "luaapi/enums_cn.json", "type": "enum", "item_key": "items"},
        {"source": "luaapi/constants.json", "output": "luaapi/constants_cn.json", "type": "constant", "item_key": "items"},
    ],
    # ç»„4: panorama
    [
        {"source": "panoramaapi/enums.json", "output": "panoramaapi/enums_cn.json", "type": "panorama_enum", "item_key": "items"},
        {"source": "panoramaevents/events.json", "output": "panoramaevents/events_cn.json", "type": "panorama_event", "item_key": "items"},
    ],
]


# ==================== Prompt æ¨¡æ¿ ====================

def get_translate_prompt(item_type: str, item: dict) -> str:
    """æ ¹æ®ç±»å‹ç”Ÿæˆç¿»è¯‘ prompt"""
    
    base_prompt = """ä½ æ˜¯ Dota2 Mod å¼€å‘ä¸“å®¶å’ŒæŠ€æœ¯æ–‡æ¡£ç¿»è¯‘ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ API å†…å®¹ç”Ÿæˆä¸­æ–‡æ–‡æ¡£ã€‚

è¦æ±‚ï¼š
1. ç¿»è¯‘è¦å‡†ç¡®ã€ä¸“ä¸šï¼Œç¬¦åˆ Dota2 æ¸¸æˆæœ¯è¯­
2. ä»£ç æ ‡è¯†ç¬¦ï¼ˆå‡½æ•°åã€å˜é‡åã€ç±»å‹åï¼‰ä¿æŒè‹±æ–‡ä¸ç¿»è¯‘
3. è¿”å›æ ‡å‡† JSON æ ¼å¼ï¼Œåªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹
4. å¯¹äºæ¯ä¸ªéœ€è¦ç¿»è¯‘çš„ _cn å­—æ®µï¼Œå¡«å…¥å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘

Dota2 å¸¸ç”¨æœ¯è¯­å‚è€ƒï¼š
- hero = è‹±é›„
- ability = æŠ€èƒ½
- modifier = ä¿®æ”¹å™¨/buff
- item = ç‰©å“
- unit = å•ä½
- entity = å®ä½“
- damage = ä¼¤å®³
- cooldown = å†·å´æ—¶é—´
- mana = é­”æ³•å€¼
- health = ç”Ÿå‘½å€¼
- armor = æŠ¤ç”²
- attack = æ”»å‡»

"""
    
    if item_type == "game_event":
        # åªæå–å¿…è¦ä¿¡æ¯ï¼Œå‡å°‘ token æ¶ˆè€—
        params_info = []
        for p in item.get("parameters", []):
            params_info.append({"name": p.get("name"), "type": p.get("type")})
        
        simplified = {
            "name": item.get("name"),
            "signature": item.get("signature"),
            "parameters": params_info
        }
        
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 Game Eventï¼ˆæ¸¸æˆäº‹ä»¶ï¼‰ï¼š
{json.dumps(simplified, ensure_ascii=False)}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœçš„ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "name_cn": "äº‹ä»¶åç§°ä¸­æ–‡",
  "description_cn": "äº‹ä»¶æè¿°ï¼ˆä»€ä¹ˆæ—¶å€™è§¦å‘ã€æœ‰ä»€ä¹ˆç”¨ï¼‰",
  "parameters_cn": [
    {{"name": "å‚æ•°å", "description_cn": "å‚æ•°è¯´æ˜", "type_description_cn": "ç±»å‹è¯´æ˜"}}
  ]
}}

åªè¿”å›ä¸Šè¿°æ ¼å¼çš„ JSONï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®ã€‚
"""
    
    elif item_type == "class":
        # åªæå–ç±»çº§åˆ«ä¿¡æ¯ï¼Œæ–¹æ³•å¤ªå¤šä¼šå¯¼è‡´ token è¶…é™
        # åªå–å‰5ä¸ªæ–¹æ³•åä½œä¸ºå‚è€ƒ
        method_names = [m.get("name") for m in item.get("methods", [])[:5]]
        
        simplified = {
            "name": item.get("name"),
            "extends": item.get("extends"),
            "description": item.get("description"),
            "method_count": len(item.get("methods", [])),
            "sample_methods": method_names
        }
        
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 Lua API ç±»ï¼š
{json.dumps(simplified, ensure_ascii=False, indent=2)}

è¯·åªè¿”å›ç±»çº§åˆ«çš„ç¿»è¯‘ï¼ˆä¸è¦ç¿»è¯‘æ–¹æ³•ï¼‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "name_cn": "ç±»åä¸­æ–‡è¯´æ˜ï¼ˆç®€çŸ­ï¼‰",
  "description_cn": "è¿™ä¸ªç±»çš„ä½œç”¨ã€ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ï¼ˆ1-2å¥è¯ï¼‰",
  "common_usage_cn": "å¸¸è§ä½¿ç”¨åœºæ™¯"
}}

åªè¿”å›ä¸Šè¿°æ ¼å¼çš„ JSONï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®ï¼Œä¸è¦ç¿»è¯‘æ–¹æ³•ã€‚
"""
    
    elif item_type == "function":
        # ç®€åŒ–å‡½æ•°ä¿¡æ¯
        params_info = [{"name": p.get("name"), "type": p.get("type"), "isOptional": p.get("isOptional", False)} for p in item.get("parameters", [])]
        
        simplified = {
            "name": item.get("name"),
            "signature": item.get("signature"),
            "description": item.get("description"),
            "returnType": item.get("returnType"),
            "parameters": params_info
        }
        
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 Lua API å…¨å±€å‡½æ•°ï¼š
{json.dumps(simplified, ensure_ascii=False, indent=2)}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœçš„ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "name_cn": "å‡½æ•°ä¸­æ–‡å",
  "description_cn": "å‡½æ•°åŠŸèƒ½è¯¦ç»†è¯´æ˜ï¼ˆåšä»€ä¹ˆã€ä»€ä¹ˆæ—¶å€™ç”¨ï¼‰",
  "common_usage_cn": "å¸¸è§ä½¿ç”¨åœºæ™¯",
  "returnType_cn": "è¿”å›å€¼ç±»å‹è¯´æ˜",
  "returnDescription_cn": "è¿”å›å€¼å«ä¹‰è¯´æ˜",
  "parameters_cn": [
    {{"name": "å‚æ•°å", "description_cn": "å‚æ•°è¯´æ˜", "type_description_cn": "ç±»å‹è¯´æ˜"}}
  ]
}}

åªè¿”å›ä¸Šè¿°æ ¼å¼çš„ JSONï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®ã€‚
"""
    
    elif item_type in ["enum", "panorama_enum"]:
        # ç®€åŒ–æšä¸¾ä¿¡æ¯
        members_info = [{"name": m.get("name"), "value": m.get("value")} for m in item.get("members", [])]
        
        simplified = {
            "name": item.get("name"),
            "description": item.get("description"),
            "members": members_info
        }
        
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 æšä¸¾å®šä¹‰ï¼š
{json.dumps(simplified, ensure_ascii=False, indent=2)}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœçš„ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "name_cn": "æšä¸¾ä¸­æ–‡å",
  "description_cn": "æšä¸¾ç”¨é€”è¯´æ˜ï¼ˆä»€ä¹ˆæ—¶å€™ç”¨ã€æœ‰å“ªäº›å€¼ï¼‰",
  "common_usage_cn": "å¸¸è§ä½¿ç”¨åœºæ™¯",
  "members_cn": [
    {{"name": "æˆå‘˜å", "description_cn": "è¯¥å€¼çš„å«ä¹‰è¯´æ˜"}}
  ]
}}

åªè¿”å›ä¸Šè¿°æ ¼å¼çš„ JSONï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®ã€‚
"""
    
    elif item_type in ["panorama_event"]:
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 Panorama UI äº‹ä»¶ï¼š

{json.dumps(item, ensure_ascii=False, indent=2)}

è¯·å¡«å……ä»¥ä¸‹ä¸­æ–‡å­—æ®µå¹¶è¿”å›å®Œæ•´ JSONï¼š
- name_cn: äº‹ä»¶åçš„ä¸­æ–‡ç¿»è¯‘
- description_cn: äº‹ä»¶çš„è¯¦ç»†ä¸­æ–‡æè¿°
- æ¯ä¸ª parameter çš„ description_cn: å‚æ•°è¯´æ˜

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
    
    elif item_type == "constant":
        simplified = {
            "name": item.get("name"),
            "value": item.get("value"),
            "valueType": item.get("valueType")
        }
        
        return base_prompt + f"""
è¿™æ˜¯ä¸€ä¸ª Dota2 å¸¸é‡å®šä¹‰ï¼š
{json.dumps(simplified, ensure_ascii=False, indent=2)}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœçš„ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "name_cn": "å¸¸é‡ä¸­æ–‡å",
  "description_cn": "å¸¸é‡ç”¨é€”è¯´æ˜ï¼ˆè¿™ä¸ªå€¼ä»£è¡¨ä»€ä¹ˆã€ä»€ä¹ˆæ—¶å€™ç”¨ï¼‰",
  "common_usage_cn": "å¸¸è§ä½¿ç”¨åœºæ™¯"
}}

åªè¿”å›ä¸Šè¿°æ ¼å¼çš„ JSONï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®ã€‚
"""
    
    return base_prompt + f"""
è¯·ç¿»è¯‘ä»¥ä¸‹å†…å®¹çš„ _cn å­—æ®µï¼š

{json.dumps(item, ensure_ascii=False, indent=2)}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""


# ==================== ç¿»è¯‘é€»è¾‘ ====================

def load_progress() -> dict:
    """åŠ è½½è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with progress_lock:
        if PROGRESS_FILE.exists():
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}


def save_progress(progress: dict):
    """ä¿å­˜è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with progress_lock:
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)


def load_failed() -> dict:
    """åŠ è½½å¤±è´¥è®°å½•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with failed_lock:
        if FAILED_FILE.exists():
            with open(FAILED_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}


def save_failed(failed: dict):
    """ä¿å­˜å¤±è´¥è®°å½•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with failed_lock:
        with open(FAILED_FILE, 'w', encoding='utf-8') as f:
            json.dump(failed, f, ensure_ascii=False, indent=2)


def add_failed(failed: dict, file_key: str, index: int, name: str):
    """æ·»åŠ å¤±è´¥è®°å½•"""
    if file_key not in failed:
        failed[file_key] = []
    # é¿å…é‡å¤
    if index not in failed[file_key]:
        failed[file_key].append(index)
        failed[file_key].sort()  # ä¿æŒé¡ºåº
    save_failed(failed)


def remove_failed(failed: dict, file_key: str, index: int):
    """ç§»é™¤å¤±è´¥è®°å½•ï¼ˆé‡è¯•æˆåŠŸåï¼‰"""
    if file_key in failed and index in failed[file_key]:
        failed[file_key].remove(index)
        if not failed[file_key]:
            del failed[file_key]
        save_failed(failed)


def fix_truncated_json(json_str: str) -> str:
    """ä¿®å¤æˆªæ–­çš„ JSON å­—ç¬¦ä¸²"""
    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²ä¸­é—´
    in_string = False
    escape = False
    last_quote_pos = -1
    
    for i, c in enumerate(json_str):
        if escape:
            escape = False
            continue
        if c == '\\':
            escape = True
            continue
        if c == '"':
            in_string = not in_string
            if in_string:
                last_quote_pos = i
    
    fixed = json_str.rstrip()
    
    # å¦‚æœåœ¨å­—ç¬¦ä¸²ä¸­é—´æˆªæ–­ï¼Œæ·»åŠ å¼•å·
    if in_string:
        fixed += '"'
    
    # å¾ªç¯ç§»é™¤å°¾éƒ¨ä¸å®Œæ•´çš„éƒ¨åˆ†
    max_iterations = 10
    for _ in range(max_iterations):
        fixed = fixed.rstrip()
        if not fixed:
            break
            
        last_char = fixed[-1]
        
        # å¦‚æœä»¥é€—å·ç»“å°¾ï¼Œç§»é™¤
        if last_char == ',':
            fixed = fixed[:-1]
            continue
        
        # å¦‚æœä»¥å†’å·ç»“å°¾ï¼Œæ·»åŠ ç©ºå€¼
        if last_char == ':':
            fixed += '""'
            continue
        
        # å¦‚æœä»¥ { å¼€å¤´ä½†æ²¡å†…å®¹
        if last_char == '{':
            fixed += '}'
            continue
            
        # å¦‚æœä»¥ [ å¼€å¤´ä½†æ²¡å†…å®¹
        if last_char == '[':
            fixed += ']'
            continue
        
        # å¦‚æœä»¥å¼•å·ç»“å°¾ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„é”®å€¼å¯¹
        if last_char == '"':
            # æ£€æŸ¥å‰é¢æ˜¯å¦æ˜¯ : æˆ– , æˆ– { æˆ– [
            # å¦‚æœæ˜¯ "key": "value" å½¢å¼ï¼Œæ˜¯å®Œæ•´çš„
            break
            
        break
    
    # è®¡ç®—å¹¶æ·»åŠ ç¼ºå°‘çš„é—­åˆæ‹¬å·
    # éœ€è¦æŒ‰æ­£ç¡®é¡ºåºé—­åˆï¼šå…ˆ }ï¼Œå† ]ï¼Œäº¤æ›¿è¿›è¡Œ
    open_braces = fixed.count('{') - fixed.count('}')
    open_brackets = fixed.count('[') - fixed.count(']')
    
    # åˆ†æç»“æ„ï¼ŒæŒ‰æ­£ç¡®é¡ºåºé—­åˆ
    # ç®€å•ç­–ç•¥ï¼šäº¤æ›¿æ·»åŠ  } å’Œ ]
    while open_braces > 0 or open_brackets > 0:
        # å…ˆé—­åˆæœ€å†…å±‚çš„ {
        if open_braces > 0:
            fixed += '}'
            open_braces -= 1
        # å†é—­åˆ [
        if open_brackets > 0:
            fixed += ']'
            open_brackets -= 1
    
    return fixed


def parse_json_response(response: str) -> dict:
    """è§£æ AI è¿”å›çš„ JSONï¼Œèƒ½å¤„ç†æˆªæ–­å’Œæ ¼å¼é”™è¯¯çš„æƒ…å†µ"""
    import re
    
    # æ¸…ç†å“åº”
    response = response.strip()
    
    # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    if response.startswith('```'):
        response = re.sub(r'^```(?:json)?\s*', '', response)
        response = re.sub(r'\s*```$', '', response)
    
    # ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é”™è¯¯
    # 1. ä¿®å¤ç¼ºå°‘å¼•å·çš„é”®åï¼Œå¦‚: description": â†’ "description":
    response = re.sub(r'(\s)([a-zA-Z_][a-zA-Z0-9_]*)(\s*:\s*)', r'\1"\2"\3', response)
    # 2. ä¿®å¤é‡å¤çš„å¼•å·
    response = re.sub(r'""([a-zA-Z_][a-zA-Z0-9_]*)""', r'"\1"', response)
    
    # 1. å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(response)
    except:
        pass
    
    # 2. æ‰¾åˆ° JSON å¼€å§‹ä½ç½®
    start = response.find('{')
    if start == -1:
        raise ValueError(f"æ— æ³•æ‰¾åˆ° JSON å¼€å§‹: {response[:100]}")
    
    json_str = response[start:]
    
    # 3. å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        pass
    
    # 4. å°è¯•ä¿®å¤æˆªæ–­çš„ JSON
    fixed = fix_truncated_json(json_str)
    try:
        return json.loads(fixed)
    except json.JSONDecodeError:
        pass
    
    # 5. æ›´æ¿€è¿›çš„ä¿®å¤ï¼šæ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é”®å€¼å¯¹
    # å°è¯•åœ¨ä¸åŒä½ç½®æˆªæ–­å¹¶ä¿®å¤
    for end_marker in ['},', '},\n', '",', '"\n', '],', ']\n']:
        last_pos = json_str.rfind(end_marker)
        if last_pos > 0:
            truncated = json_str[:last_pos + len(end_marker) - 1]  # ä¸åŒ…å«é€—å·
            fixed = fix_truncated_json(truncated)
            try:
                return json.loads(fixed)
            except:
                continue
    
    # 6. æœ€åå°è¯•ï¼šä»åå¾€å‰æ‰¾å®Œæ•´çš„ }
    for i in range(len(json_str) - 1, 0, -1):
        if json_str[i] == '}':
            test_str = json_str[:i+1]
            fixed = fix_truncated_json(test_str)
            try:
                return json.loads(fixed)
            except:
                continue
    
    raise ValueError(f"æ— æ³•è§£æ JSON: {response[:200]}")


def merge_translation(original: dict, translation: dict, item_type: str) -> dict:
    """å°†ç¿»è¯‘ç»“æœåˆå¹¶åˆ°åŸå§‹æ•°æ®ä¸­"""
    import copy
    result = copy.deepcopy(original)  # æ·±æ‹·è´é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    
    # åˆå¹¶é¡¶å±‚å­—æ®µ
    top_level_keys = [
        "name_cn", "description_cn", "example_ts", "notes_cn", "common_usage_cn", 
        "usage_cn", "returnType_cn", "returnDescription_cn", "warnings_cn"
    ]
    for key in top_level_keys:
        if key in translation and translation[key]:
            result[key] = translation[key]
    
    # åˆå¹¶å‚æ•°ç¿»è¯‘ (game_event, function, panorama_event)
    if "parameters_cn" in translation:
        params_cn = {p["name"]: p for p in translation["parameters_cn"] if "name" in p}
        for param in result.get("parameters", []):
            pname = param.get("name")
            if pname in params_cn:
                param["description_cn"] = params_cn[pname].get("description_cn", "")
                param["type_description_cn"] = params_cn[pname].get("type_description_cn", "")
    
    # åˆå¹¶æ–¹æ³•ç¿»è¯‘ (class)
    if item_type == "class" and "methods_cn" in translation:
        methods_cn = {m["name"]: m for m in translation["methods_cn"] if "name" in m}
        for method in result.get("methods", []):
            mname = method.get("name")
            if mname in methods_cn:
                m_trans = methods_cn[mname]
                method["name_cn"] = m_trans.get("name_cn", "")
                method["description_cn"] = m_trans.get("description_cn", "")
                method["returnType_cn"] = m_trans.get("returnType_cn", "")
                method["returnDescription_cn"] = m_trans.get("returnDescription_cn", "")
                method["notes_cn"] = m_trans.get("notes_cn", "")
                method["warnings_cn"] = m_trans.get("warnings_cn", "")
                method["common_usage_cn"] = m_trans.get("common_usage_cn", "")
                
                # åˆå¹¶æ–¹æ³•çš„å‚æ•°ç¿»è¯‘
                if "parameters_cn" in m_trans:
                    m_params_cn = {p["name"]: p for p in m_trans["parameters_cn"] if "name" in p}
                    for param in method.get("parameters", []):
                        pname = param.get("name")
                        if pname in m_params_cn:
                            param["description_cn"] = m_params_cn[pname].get("description_cn", "")
                            param["type_description_cn"] = m_params_cn[pname].get("type_description_cn", "")
    
    # åˆå¹¶ç±»å­—æ®µç¿»è¯‘ (class fields)
    if item_type == "class" and "fields_cn" in translation:
        fields_cn = {f["name"]: f for f in translation["fields_cn"] if "name" in f}
        for field in result.get("fields", []):
            fname = field.get("name")
            if fname in fields_cn:
                field["description_cn"] = fields_cn[fname].get("description_cn", "")
                field["type_description_cn"] = fields_cn[fname].get("type_description_cn", "")
                field["notes_cn"] = fields_cn[fname].get("notes_cn", "")
    
    # åˆå¹¶æšä¸¾æˆå‘˜ç¿»è¯‘ (enum)
    if item_type in ["enum", "panorama_enum"] and "members_cn" in translation:
        members_cn = {m["name"]: m for m in translation["members_cn"] if "name" in m}
        for member in result.get("members", []):
            mname = member.get("name")
            if mname in members_cn:
                member["description_cn"] = members_cn[mname].get("description_cn", "")
    
    # ==================== ç¡®ä¿æ‰€æœ‰ç¿»è¯‘å­—æ®µå­˜åœ¨ ====================
    
    # é¡¶å±‚å­—æ®µ
    result.setdefault("name_cn", "")
    result.setdefault("description_cn", "")
    result.setdefault("example_ts", "")
    result.setdefault("notes_cn", "")
    result.setdefault("warnings_cn", "")
    result.setdefault("common_usage_cn", "")
    result.setdefault("related", [])
    result.setdefault("see_also", [])
    result.setdefault("tags", [])
    
    # function/class é¡¶å±‚çš„è¿”å›å€¼å­—æ®µ
    if item_type in ["function"]:
        result.setdefault("returnType_cn", "")
        result.setdefault("returnDescription_cn", "")
    
    # å‚æ•°å­—æ®µ (function, panorama_event)
    for param in result.get("parameters", []):
        param.setdefault("description_cn", "")
        param.setdefault("type_description_cn", "")
    
    # æ–¹æ³•å­—æ®µ (class)
    for method in result.get("methods", []):
        method.setdefault("name_cn", "")
        method.setdefault("description_cn", "")
        method.setdefault("returnType_cn", "")
        method.setdefault("returnDescription_cn", "")
        method.setdefault("notes_cn", "")
        method.setdefault("warnings_cn", "")
        method.setdefault("common_usage_cn", "")
        for param in method.get("parameters", []):
            param.setdefault("description_cn", "")
            param.setdefault("type_description_cn", "")
    
    # ç±»å­—æ®µ (class fields)
    for field in result.get("fields", []):
        field.setdefault("description_cn", "")
        field.setdefault("type_description_cn", "")
        field.setdefault("notes_cn", "")
    
    # æšä¸¾æˆå‘˜å­—æ®µ (enum)
    for member in result.get("members", []):
        member.setdefault("description_cn", "")
    
    return result


def translate_methods_batch(pool: SmartAPIPool, class_name: str, methods: list, batch_size: int = 5) -> dict:
    """
    åˆ†æ‰¹ç¿»è¯‘ç±»çš„æ–¹æ³•
    Returns: {method_name: translation_dict}
    """
    all_translations = {}
    total_batches = (len(methods) + batch_size - 1) // batch_size
    
    for batch_idx in range(total_batches):
        start = batch_idx * batch_size
        end = min(start + batch_size, len(methods))
        batch = methods[start:end]
        
        # æç®€æ–¹æ³•ä¿¡æ¯
        batch_info = []
        for m in batch:
            params = [p.get("name") for p in m.get("parameters", [])]
            batch_info.append({
                "n": m.get("name"),
                "d": (m.get("description") or "")[:100],  # é™åˆ¶æè¿°é•¿åº¦
                "p": params
            })
        
        # æç®€ prompt
        prompt = f"""ç¿»è¯‘Dota2æ–¹æ³•:
{json.dumps(batch_info, ensure_ascii=False)}
è¿”å›JSON:{{"m":[{{"n":"æ–¹æ³•å","c":"ä¸­æ–‡å","d":"è¯´æ˜","p":[{{"n":"å‚æ•°å","d":"è¯´æ˜"}}]}}]}}"""
        
        response = pool.chat_safe([
            {"role": "system", "content": "åªè¿”å›JSONã€‚å­—æ®µånameå¿…é¡»ä¿æŒè‹±æ–‡åŸæ ·ã€‚"},
            {"role": "user", "content": prompt}
        ], model=MODEL)
        
        if response:
            try:
                result = parse_json_response(response)
                # æ”¯æŒå¤šç§æ ¼å¼
                methods_list = result.get("methods_cn", result.get("m", []))
                success_count = 0
                for m in methods_list:
                    # æ”¯æŒ name æˆ– n ä½œä¸ºæ–¹æ³•å
                    mname = m.get("name", m.get("n"))
                    if mname:
                        # è½¬æ¢ç®€åŒ–æ ¼å¼åˆ°æ ‡å‡†æ ¼å¼
                        all_translations[mname] = {
                            "name": mname,
                            "name_cn": m.get("name_cn", m.get("c", m.get("n_cn", ""))),
                            "description_cn": m.get("description_cn", m.get("d", "")),
                            "returnType_cn": m.get("returnType_cn", m.get("r", "")),
                            "returnDescription_cn": m.get("returnDescription_cn", ""),
                            "parameters_cn": []
                        }
                        # å¤„ç†å‚æ•°
                        params = m.get("parameters_cn", m.get("p", []))
                        for p in params:
                            pname = p.get("name", p.get("n")) if isinstance(p, dict) else None
                            if pname:
                                all_translations[mname]["parameters_cn"].append({
                                    "name": pname,
                                    "description_cn": p.get("description_cn", p.get("d", "")),
                                    "type_description_cn": p.get("type_description_cn", p.get("t", ""))
                                })
                        success_count += 1
                log(f"      æ–¹æ³•æ‰¹æ¬¡ {batch_idx+1}/{total_batches}: âœ… {success_count} ä¸ª")
            except Exception as e:
                log(f"      æ–¹æ³•æ‰¹æ¬¡ {batch_idx+1}/{total_batches}: âŒ {str(e)[:60]}")
        else:
            log(f"      æ–¹æ³•æ‰¹æ¬¡ {batch_idx+1}/{total_batches}: âŒ è¯·æ±‚å¤±è´¥")
        
        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    return all_translations


def translate_class_item(pool: SmartAPIPool, item: dict, index: int, total: int) -> tuple:
    """
    ç¿»è¯‘å•ä¸ª class æ¡ç›®ï¼ˆåŒ…æ‹¬åˆ†æ‰¹ç¿»è¯‘æ–¹æ³•ï¼‰
    Returns: (translated_item, success: bool)
    """
    import copy
    name = item.get("name", f"class_{index}")
    start_time = time.time()
    
    log(f"[{index+1}/{total}] å¼€å§‹ç¿»è¯‘ç±»: {name}")
    
    methods = item.get("methods", [])
    log(f"      åŒ…å« {len(methods)} ä¸ªæ–¹æ³•")
    
    # ç¬¬ä¸€æ­¥ï¼šç¿»è¯‘ç±»æœ¬èº«
    prompt = get_translate_prompt("class", item)
    
    response = pool.chat_safe([
        {"role": "system", "content": "åªè¿”å›çº¯ JSONï¼Œä¸è¦ markdownã€‚ç›´æ¥ä»¥ { å¼€å¤´ã€‚"},
        {"role": "user", "content": prompt}
    ], model=MODEL)
    
    result = copy.deepcopy(item)
    class_success = False
    
    if response:
        try:
            translation = parse_json_response(response)
            # åˆå¹¶ç±»çº§åˆ«ç¿»è¯‘
            for key in ["name_cn", "description_cn", "common_usage_cn", "notes_cn"]:
                if key in translation and translation[key]:
                    result[key] = translation[key]
            class_success = True
            log(f"      ç±»ä¿¡æ¯: âœ…")
        except Exception as e:
            log(f"      ç±»ä¿¡æ¯: âŒ {e}")
    
    # ç¬¬äºŒæ­¥ï¼šåˆ†æ‰¹ç¿»è¯‘æ–¹æ³•ï¼ˆå¦‚æœæœ‰æ–¹æ³•ï¼‰
    if methods:
        # æ¯æ‰¹3ä¸ªæ–¹æ³•ï¼Œé¿å… token è¶…é™å¯¼è‡´ JSON æˆªæ–­
        methods_translations = translate_methods_batch(pool, name, methods, batch_size=3)
        
        # åˆå¹¶æ–¹æ³•ç¿»è¯‘
        for method in result.get("methods", []):
            mname = method.get("name")
            if mname in methods_translations:
                m_trans = methods_translations[mname]
                method["name_cn"] = m_trans.get("name_cn", "")
                method["description_cn"] = m_trans.get("description_cn", "")
                method["returnType_cn"] = m_trans.get("returnType_cn", "")
                method["returnDescription_cn"] = m_trans.get("returnDescription_cn", "")
                
                # åˆå¹¶å‚æ•°ç¿»è¯‘
                if "parameters_cn" in m_trans:
                    params_cn = {p["name"]: p for p in m_trans["parameters_cn"] if "name" in p}
                    for param in method.get("parameters", []):
                        pname = param.get("name")
                        if pname in params_cn:
                            param["description_cn"] = params_cn[pname].get("description_cn", "")
                            param["type_description_cn"] = params_cn[pname].get("type_description_cn", "")
        
        translated_methods = sum(1 for m in result.get("methods", []) if m.get("name_cn"))
        log(f"      æ–¹æ³•ç¿»è¯‘: {translated_methods}/{len(methods)}")
    
    # ç¡®ä¿æ‰€æœ‰å­—æ®µæœ‰é»˜è®¤å€¼
    result = merge_translation(result, {}, "class")
    
    elapsed = time.time() - start_time
    log(f"[{index+1}/{total}] {'âœ…' if class_success else 'âš ï¸'} å®Œæˆ: {name} (è€—æ—¶ {elapsed:.1f}s)")
    
    return result, class_success


def translate_item(pool: SmartAPIPool, item: dict, item_type: str, index: int, total: int) -> tuple:
    """
    ç¿»è¯‘å•ä¸ªæ¡ç›®
    Returns: (translated_item, success: bool)
    """
    # class ç±»å‹ä½¿ç”¨ä¸“é—¨çš„ç¿»è¯‘å‡½æ•°
    if item_type == "class":
        return translate_class_item(pool, item, index, total)
    
    name = item.get("name", item.get("eventName", f"item_{index}"))
    start_time = time.time()
    
    log(f"[{index+1}/{total}] å¼€å§‹ç¿»è¯‘: {name}")
    
    prompt = get_translate_prompt(item_type, item)
    
    response = pool.chat_safe([
        {"role": "system", "content": "ä½ æ˜¯ Dota2 Mod å¼€å‘ä¸“å®¶å’ŒæŠ€æœ¯æ–‡æ¡£ç¿»è¯‘ä¸“å®¶ã€‚\n\né‡è¦è§„åˆ™ï¼š\n1. åªè¿”å›çº¯ JSONï¼Œä¸è¦ markdown ä»£ç å—\n2. ä¸è¦è¿”å› ```json æˆ– ```\n3. ç›´æ¥ä»¥ { å¼€å¤´ï¼Œä»¥ } ç»“å°¾\n4. ç¡®ä¿ JSON å®Œæ•´ï¼Œä¸è¦æˆªæ–­\n5. åªè¿”å›ç¿»è¯‘å­—æ®µï¼Œä¸è¦è¿”å›åŸå§‹æ•°æ®"},
        {"role": "user", "content": prompt}
    ], model=MODEL)
    
    elapsed = time.time() - start_time
    
    if response is None:
        log(f"[{index+1}/{total}] âŒ ç¿»è¯‘å¤±è´¥: {name} (è€—æ—¶ {elapsed:.1f}s)", "error")
        return item, False
    
    try:
        translation = parse_json_response(response)
        # åˆå¹¶ç¿»è¯‘ç»“æœåˆ°åŸå§‹æ•°æ®
        result = merge_translation(item, translation, item_type)
        log(f"[{index+1}/{total}] âœ… å®Œæˆ: {name} (è€—æ—¶ {elapsed:.1f}s)")
        return result, True
    except Exception as e:
        log(f"[{index+1}/{total}] âŒ JSONè§£æå¤±è´¥: {name} - {e}", "error")
        return item, False


def translate_file(pool: SmartAPIPool, task: dict, progress: dict, failed: dict, global_stats: dict, worker_id: int = 0):
    """ç¿»è¯‘å•ä¸ªæ–‡ä»¶"""
    source_path = DATA_DIR / task["source"]
    output_path = DATA_DIR / task["output"]
    item_type = task["type"]
    item_key = task["item_key"]
    progress_key = task["source"]
    
    # è·å–ç›®å½•åä½œä¸ºæ ‡è¯†
    dir_name = task["source"].split("/")[0]
    
    log("=" * 60, worker_id=worker_id)
    log(f"ğŸ“ [{dir_name}] å¼€å§‹ç¿»è¯‘: {task['source']}", worker_id=worker_id)
    log(f"   è¾“å‡º: {task['output']}", worker_id=worker_id)
    log(f"   ç±»å‹: {item_type}", worker_id=worker_id)
    log("=" * 60, worker_id=worker_id)
    
    # åŠ è½½æºæ•°æ®
    with open(source_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    items = data.get(item_key, [])
    total = len(items)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç¿»è¯‘çš„è¾“å‡ºæ–‡ä»¶
    translated_data = None
    if output_path.exists():
        with open(output_path, 'r', encoding='utf-8') as f:
            translated_data = json.load(f)
    else:
        translated_data = {
            "metadata": data.get("metadata", {}),
            item_key: []
        }
        translated_data["metadata"]["translated_at"] = datetime.now().isoformat()
        translated_data["metadata"]["model"] = MODEL
    
    # è·å–å·²ç¿»è¯‘çš„ç´¢å¼•
    start_index = progress.get(progress_key, 0)
    
    # è·å–ä¹‹å‰å¤±è´¥çš„æ¡ç›®
    failed_indices = failed.get(progress_key, [])
    
    log(f"ğŸ“Š [{dir_name}] è¿›åº¦: {start_index}/{total} ({start_index*100//total if total > 0 else 0}%)", worker_id=worker_id)
    log(f"   å¾…ç¿»è¯‘: {total - start_index} æ¡", worker_id=worker_id)
    if failed_indices:
        log(f"   âš ï¸ ä¹‹å‰å¤±è´¥éœ€é‡è¯•: {len(failed_indices)} æ¡", worker_id=worker_id)
    
    # ç¡®ä¿å·²ç¿»è¯‘çš„æ•°æ®åˆ—è¡¨é•¿åº¦æ­£ç¡®
    while len(translated_data[item_key]) < start_index:
        translated_data[item_key].append(items[len(translated_data[item_key])])
    
    file_start_time = time.time()
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šé‡è¯•ä¹‹å‰å¤±è´¥çš„æ¡ç›® ==========
    if failed_indices:
        log(f"ğŸ”„ [{dir_name}] é‡è¯• {len(failed_indices)} ä¸ªå¤±è´¥æ¡ç›®...", worker_id=worker_id)
        retry_success = 0
        retry_failed = 0
        
        for idx in failed_indices[:]:  # ç”¨åˆ‡ç‰‡å¤åˆ¶ï¼Œé¿å…ä¿®æ”¹æ—¶å‡ºé”™
            if idx >= total:
                continue
            
            item = items[idx]
            name = item.get("name", item.get("eventName", f"item_{idx}"))
            log(f"  ğŸ”„ [{dir_name}] é‡è¯• [{idx+1}/{total}]: {name}", worker_id=worker_id)
            
            translated_item, success = translate_item(pool, item, item_type, idx, total)
            
            if success:
                # æ›´æ–°ç¿»è¯‘ç»“æœ
                while len(translated_data[item_key]) <= idx:
                    translated_data[item_key].append(items[len(translated_data[item_key])])
                translated_data[item_key][idx] = translated_item
                
                # ä»å¤±è´¥åˆ—è¡¨ç§»é™¤
                remove_failed(failed, progress_key, idx)
                retry_success += 1
                log(f"  âœ… [{dir_name}] é‡è¯•æˆåŠŸ: {name}", worker_id=worker_id)
            else:
                retry_failed += 1
                log(f"  âŒ [{dir_name}] é‡è¯•å¤±è´¥: {name}", worker_id=worker_id)
            
            time.sleep(0.5)
        
        # ä¿å­˜é‡è¯•åçš„ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(translated_data, f, ensure_ascii=False, indent=2)
        
        log(f"  ğŸ“Š [{dir_name}] é‡è¯•ç»“æœ: æˆåŠŸ {retry_success}, å¤±è´¥ {retry_failed}", worker_id=worker_id)
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šç»§ç»­ç¿»è¯‘æ–°æ¡ç›® ==========
    if start_index < total:
        log(f"ğŸ“ [{dir_name}] ç»§ç»­ç¿»è¯‘ (ä» {start_index + 1} å¼€å§‹)...", worker_id=worker_id)
    
    consecutive_failures = 0  # è¿ç»­å¤±è´¥è®¡æ•°
    MAX_CONSECUTIVE_FAILURES = 20  # è¿ç»­å¤±è´¥è¶…è¿‡è¿™ä¸ªæ•°å°±æš‚åœ
    
    for i in range(start_index, total):
        item = items[i]
        name = item.get("name", item.get("eventName", f"item_{i}"))
        
        # æ£€æŸ¥ API æ± çŠ¶æ€
        pool_status = pool.get_status()
        if pool_status['available'] == 0:
            log(f"âŒ [{dir_name}] API Key éƒ½å·²å¤±æ•ˆï¼è¿›åº¦: {i}/{total}", "error", worker_id=worker_id)
            # ä¿å­˜å½“å‰æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(translated_data, f, ensure_ascii=False, indent=2)
            raise Exception(f"[{dir_name}] æ‰€æœ‰ API Key éƒ½å·²å¤±æ•ˆ")
        
        # ç¿»è¯‘
        log(f"[{dir_name}] [{i+1}/{total}] ç¿»è¯‘: {name}", worker_id=worker_id)
        translated_item, success = translate_item(pool, item, item_type, i, total)
        
        # æ·»åŠ åˆ°ç»“æœ
        if len(translated_data[item_key]) > i:
            translated_data[item_key][i] = translated_item
        else:
            translated_data[item_key].append(translated_item)
        
        # è®°å½•å¤±è´¥
        if not success:
            add_failed(failed, progress_key, i, name)
            consecutive_failures += 1
            log(f"  âŒ [{dir_name}] å¤±è´¥: {name}", worker_id=worker_id)
            
            # è¿ç»­å¤±è´¥å¤ªå¤šï¼Œå¯èƒ½æ˜¯ API é—®é¢˜
            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                log(f"âš ï¸ [{dir_name}] è¿ç»­ {consecutive_failures} æ¬¡å¤±è´¥ï¼Œæš‚åœ", "warning", worker_id=worker_id)
                # ä¿å­˜å½“å‰æ–‡ä»¶
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(translated_data, f, ensure_ascii=False, indent=2)
                progress[progress_key] = i + 1
                save_progress(progress)
                return  # é€€å‡ºå½“å‰æ–‡ä»¶ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæ–‡ä»¶
        else:
            consecutive_failures = 0  # æˆåŠŸåˆ™é‡ç½®
            log(f"  âœ… [{dir_name}] å®Œæˆ: {name}", worker_id=worker_id)
        
        # ä¿å­˜è¿›åº¦ï¼ˆæ¯æ¡éƒ½ä¿å­˜ï¼‰
        progress[progress_key] = i + 1
        save_progress(progress)
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with progress_lock:
            global_stats["completed"] += 1
        
        # æ¯æ¡éƒ½ä¿å­˜æ–‡ä»¶ï¼ˆç¡®ä¿ä¸ä¸¢å¤±ï¼‰
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(translated_data, f, ensure_ascii=False, indent=2)
        
        # æ¯ 5 æ¡æ‰“å°ä¸€æ¬¡çŠ¶æ€
        if (i + 1) % 5 == 0 or i == total - 1:
            elapsed = time.time() - file_start_time
            items_done = i + 1 - start_index
            avg_time = elapsed / items_done if items_done > 0 else 0
            remaining = (total - i - 1) * avg_time
            
            current_failed = len(failed.get(progress_key, []))
            log(f"ğŸ’¾ [{dir_name}] {i+1}/{total} | å¤±è´¥:{current_failed} | {avg_time:.1f}s/æ¡ | å‰©ä½™:{remaining/60:.1f}åˆ†é’Ÿ", worker_id=worker_id)
        
        # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…è¯·æ±‚è¿‡å¿«ï¼ˆå¢åŠ éšæœºæŠ–åŠ¨é¿å…å¤šçº¿ç¨‹åŒæ—¶è¯·æ±‚ï¼‰
        time.sleep(1.0 + random.random() * 0.5)  # 1.0-1.5 ç§’éšæœºå»¶è¿Ÿ
    
    elapsed = time.time() - file_start_time
    final_failed = len(failed.get(progress_key, []))
    log(f"ğŸ‰ [{dir_name}] å®Œæˆ: {task['source']} | è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | å¤±è´¥: {final_failed} æ¡", worker_id=worker_id)


def worker_translate_group(worker_id: int, api_keys: list, tasks: list, progress: dict, failed: dict, global_stats: dict, all_tasks: list = None):
    """
    Worker çº¿ç¨‹ï¼šç¿»è¯‘ä¸€ç»„ä»»åŠ¡
    æ¯ä¸ª worker ä½¿ç”¨å¤šä¸ª API Keyï¼ˆè½®æ¢ä½¿ç”¨ï¼‰
    å®Œæˆè‡ªå·±çš„ä»»åŠ¡åï¼Œä¼šå°è¯•å¸®åŠ©å…¶ä»–æœªå®Œæˆçš„ä»»åŠ¡
    """
    # åˆ›å»ºç‹¬ç«‹çš„ API æ± ï¼Œä½¿ç”¨åˆ†é…çš„å¤šä¸ª Key
    pool = SmartAPIPool(max_rpm=60, max_rpm_per_key=10)  # é™ä½å• Key é€Ÿç‡
    # æ¸…ç©ºé»˜è®¤ keys
    pool.keys_info = {}
    pool.key_order = api_keys
    pool.current_key_index = 0
    
    # æ·»åŠ åˆ†é…çš„æ‰€æœ‰ keys
    from smart_api_pool import APIKeyInfo
    for key in api_keys:
        pool.keys_info[key] = APIKeyInfo(key=key)
    
    log(f"ğŸš€ Worker {worker_id} å¯åŠ¨ï¼Œè´Ÿè´£ {len(tasks)} ä¸ªä»»åŠ¡", worker_id=worker_id)
    log(f"   åˆ†é… {len(api_keys)} ä¸ª API Keys", worker_id=worker_id)
    
    def process_task(task):
        """å¤„ç†å•ä¸ªä»»åŠ¡ï¼Œè¿”å›æ˜¯å¦æœ‰å·¥ä½œå¯åš"""
        source_path = DATA_DIR / task["source"]
        if not source_path.exists():
            log(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨: {task['source']}", "warning", worker_id=worker_id)
            return False
        
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        with open(source_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        total = len(data.get(task["item_key"], []))
        done = progress.get(task["source"], 0)
        has_failed = len(failed.get(task["source"], [])) > 0
        
        if done >= total and not has_failed:
            return False  # å·²å®Œæˆï¼Œæ— éœ€å¤„ç†
        
        try:
            translate_file(pool, task, progress, failed, global_stats, worker_id)
            return True
        except Exception as e:
            log(f"âŒ ä»»åŠ¡å¼‚å¸¸: {task['source']} - {e}", "error", worker_id=worker_id)
            return False
    
    # ç¬¬ä¸€é˜¶æ®µï¼šå¤„ç†è‡ªå·±è´Ÿè´£çš„ä»»åŠ¡
    for task in tasks:
        process_task(task)
    
    log(f"âœ… Worker {worker_id} å®Œæˆè‡ªå·±çš„ä»»åŠ¡", worker_id=worker_id)
    
    # ç¬¬äºŒé˜¶æ®µï¼šå¸®åŠ©å…¶ä»–æœªå®Œæˆçš„ä»»åŠ¡
    if all_tasks:
        log(f"ğŸ” Worker {worker_id} æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ä»»åŠ¡éœ€è¦å¸®åŠ©...", worker_id=worker_id)
        helped = False
        for task in all_tasks:
            # è·³è¿‡è‡ªå·±å·²ç»å¤„ç†è¿‡çš„
            if task in tasks:
                continue
            
            source_path = DATA_DIR / task["source"]
            if not source_path.exists():
                continue
            
            with open(source_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            total = len(data.get(task["item_key"], []))
            done = progress.get(task["source"], 0)
            has_failed = len(failed.get(task["source"], [])) > 0
            
            # å¦‚æœè¿˜æœ‰æœªå®Œæˆçš„å·¥ä½œ
            if done < total or has_failed:
                log(f"ğŸ¤ Worker {worker_id} å¸®åŠ©ç¿»è¯‘: {task['source']} ({done}/{total})", worker_id=worker_id)
                if process_task(task):
                    helped = True
        
        if not helped:
            log(f"ğŸ‘ Worker {worker_id} æ²¡æœ‰éœ€è¦å¸®åŠ©çš„ä»»åŠ¡", worker_id=worker_id)
    
    log(f"ğŸ Worker {worker_id} å®Œæˆæ‰€æœ‰å·¥ä½œ", worker_id=worker_id)


def main(parallel: int = 1):
    """
    ä¸»å‡½æ•°
    parallel: å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆ1=ä¸²è¡Œï¼Œ>1=å¹¶è¡Œï¼‰
    """
    log("=" * 60)
    log("ğŸš€ Dota2 API æ–‡æ¡£æ‰¹é‡ç¿»è¯‘")
    log(f"   æ¨¡å‹: {MODEL}")
    log(f"   æ¨¡å¼: {'å¹¶è¡Œ ' + str(parallel) + ' çº¿ç¨‹' if parallel > 1 else 'ä¸²è¡Œ'}")
    log(f"   æ—¶é—´: {datetime.now().isoformat()}")
    log(f"   æ—¥å¿—: {LOG_FILE}")
    log("=" * 60)
    
    # åŠ è½½ API Keys
    keys_file = Path(__file__).parent.parent / "valid_api_keys.json"
    with open(keys_file, 'r') as f:
        all_keys = json.load(f)["keys"]
    
    log(f"\nğŸ”‘ å¯ç”¨ API Keys: {len(all_keys)} ä¸ª")
    
    # åŠ è½½è¿›åº¦å’Œå¤±è´¥è®°å½•
    progress = load_progress()
    failed = load_failed()
    
    # ç»Ÿè®¡
    total_items = 0
    completed_items = 0
    total_failed = 0
    
    log("\nğŸ“‹ ä»»åŠ¡åˆ—è¡¨:")
    for task in TRANSLATE_TASKS:
        source_path = DATA_DIR / task["source"]
        if source_path.exists():
            with open(source_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            count = len(data.get(task["item_key"], []))
            done = progress.get(task["source"], 0)
            failed_count = len(failed.get(task["source"], []))
            total_items += count
            completed_items += done
            total_failed += failed_count
            status = "âœ…" if done >= count else "â³"
            failed_str = f" (âŒå¤±è´¥: {failed_count})" if failed_count > 0 else ""
            log(f"   {status} {task['source']}: {done}/{count}{failed_str}")
    
    log(f"\nğŸ“Š æ€»è¿›åº¦: {completed_items}/{total_items} ({completed_items*100//total_items if total_items > 0 else 0}%)")
    if total_failed > 0:
        log(f"   âš ï¸ å¾…é‡è¯•: {total_failed} æ¡å¤±è´¥è®°å½•")
    
    # å…¨å±€ç»Ÿè®¡
    global_stats = {
        "total": total_items,
        "completed": completed_items,
        "start_time": time.time()
    }
    
    # å¼€å§‹ç¿»è¯‘
    if parallel > 1:
        log(f"\nğŸ”€ å¹¶è¡Œæ¨¡å¼: {parallel} ä¸ªçº¿ç¨‹åŒæ—¶å·¥ä½œ")
        log(f"   æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„ API Key")
        for i, group in enumerate(TASK_GROUPS[:parallel]):
            tasks_str = ", ".join([t["source"].split("/")[0] for t in group])
            log(f"   çº¿ç¨‹ {i+1}: {tasks_str}")
    
    input("\næŒ‰ Enter å¼€å§‹ç¿»è¯‘ï¼ˆCtrl+C å¯éšæ—¶ä¸­æ–­ï¼Œè¿›åº¦ä¼šè‡ªåŠ¨ä¿å­˜ï¼‰...")
    
    log("\nğŸƒ å¼€å§‹ç¿»è¯‘ä»»åŠ¡...")
    
    try:
        if parallel > 1:
            # å¹¶è¡Œæ¨¡å¼
            num_workers = min(parallel, len(TASK_GROUPS))
            threads = []
            
            # å°† API Keys å¹³å‡åˆ†é…ç»™å„ä¸ª Worker
            # æ¯ä¸ª Worker è·å¾—å¤šä¸ª Keyï¼Œå¯ä»¥åœ¨é™æµæ—¶åˆ‡æ¢
            keys_per_worker = max(1, len(all_keys) // num_workers)
            
            log(f"\nğŸ”‘ Key åˆ†é…ç­–ç•¥: {len(all_keys)} ä¸ª Key / {num_workers} ä¸ª Worker = æ¯ä¸ª Worker {keys_per_worker} ä¸ª Key")
            
            # æ”¶é›†æ‰€æœ‰ä»»åŠ¡ï¼ˆç”¨äºå®Œæˆåå¸®åŠ©å…¶ä»–çº¿ç¨‹ï¼‰
            all_tasks_flat = [task for group in TASK_GROUPS for task in group]
            
            for i in range(num_workers):
                # åˆ†é… Keys: Worker i è·å¾— keys[i*n : (i+1)*n]
                start_idx = i * keys_per_worker
                end_idx = start_idx + keys_per_worker if i < num_workers - 1 else len(all_keys)
                worker_keys = all_keys[start_idx:end_idx]
                
                tasks = TASK_GROUPS[i]
                
                t = threading.Thread(
                    target=worker_translate_group,
                    args=(i + 1, worker_keys, tasks, progress, failed, global_stats, all_tasks_flat),
                    daemon=True
                )
                threads.append(t)
                t.start()
                # é”™å¼€å¯åŠ¨æ—¶é—´ï¼Œé¿å…åŒæ—¶è¯·æ±‚è§¦å‘ IP é™æµ
                if i < num_workers - 1:
                    log(f"â³ ç­‰å¾… 5 ç§’åå¯åŠ¨ä¸‹ä¸€ä¸ªçº¿ç¨‹...")
                    time.sleep(5)
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for t in threads:
                t.join()
        else:
            # ä¸²è¡Œæ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            pool = SmartAPIPool(max_rpm=200, max_rpm_per_key=3)
            
            for task in TRANSLATE_TASKS:
                source_path = DATA_DIR / task["source"]
                if not source_path.exists():
                    log(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {task['source']}", "warning")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆï¼ˆä½†å¦‚æœæœ‰å¤±è´¥è®°å½•ï¼Œä»éœ€å¤„ç†ï¼‰
                with open(source_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                total = len(data.get(task["item_key"], []))
                done = progress.get(task["source"], 0)
                has_failed = len(failed.get(task["source"], [])) > 0
                
                if done >= total and not has_failed:
                    log(f"âœ… è·³è¿‡å·²å®Œæˆ: {task['source']}")
                    continue
                
                translate_file(pool, task, progress, failed, global_stats, worker_id=0)
            
    except KeyboardInterrupt:
        log("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜", "warning")
        log(f"   è¿›åº¦æ–‡ä»¶: {PROGRESS_FILE}")
        log(f"   å¤±è´¥è®°å½•: {FAILED_FILE}")
    
    # æœ€ç»ˆç»Ÿè®¡
    total_time = time.time() - global_stats["start_time"]
    final_failed = sum(len(v) for v in failed.values())
    log("\n" + "=" * 60)
    log("ğŸ ç¿»è¯‘ä»»åŠ¡ç»“æŸ")
    log(f"   å®Œæˆ: {global_stats['completed']}/{global_stats['total']}")
    log(f"   å¤±è´¥: {final_failed} æ¡ï¼ˆä¸‹æ¬¡è¿è¡Œä¼šè‡ªåŠ¨é‡è¯•ï¼‰")
    log(f"   è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    log("=" * 60)


def reset_progress():
    """é‡ç½®æ‰€æœ‰è¿›åº¦"""
    import shutil
    
    log("ğŸ—‘ï¸ é‡ç½®ç¿»è¯‘è¿›åº¦...")
    
    # åˆ é™¤è¿›åº¦æ–‡ä»¶
    if PROGRESS_FILE.exists():
        os.remove(PROGRESS_FILE)
        log(f"   åˆ é™¤: {PROGRESS_FILE.name}")
    
    # åˆ é™¤å¤±è´¥è®°å½•
    if FAILED_FILE.exists():
        os.remove(FAILED_FILE)
        log(f"   åˆ é™¤: {FAILED_FILE.name}")
    
    # åˆ é™¤æ‰€æœ‰ *_cn.json æ–‡ä»¶
    for task in TRANSLATE_TASKS:
        output_path = DATA_DIR / task["output"]
        if output_path.exists():
            os.remove(output_path)
            log(f"   åˆ é™¤: {task['output']}")
    
    # åˆ é™¤ API æ± çŠ¶æ€
    state_file = Path(__file__).parent.parent / "api_pool_state.json"
    if state_file.exists():
        os.remove(state_file)
        log(f"   åˆ é™¤: api_pool_state.json")
    
    log("âœ… è¿›åº¦å·²é‡ç½®ï¼Œå¯ä»¥ä»å¤´å¼€å§‹ç¿»è¯‘")


def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("""
Dota2 API æ–‡æ¡£æ‰¹é‡ç¿»è¯‘å·¥å…·

ç”¨æ³•:
  python translate_all.py [é€‰é¡¹]

é€‰é¡¹:
  (æ— å‚æ•°)     ä¸²è¡Œæ¨¡å¼ï¼Œæ–­ç‚¹ç»­ä¼ 
  -p N         å¹¶è¡Œæ¨¡å¼ï¼ŒN ä¸ªçº¿ç¨‹åŒæ—¶ç¿»è¯‘ï¼ˆæœ€å¤š 4 ä¸ªï¼‰
  --reset      é‡ç½®æ‰€æœ‰è¿›åº¦ï¼Œä»å¤´å¼€å§‹
  --status     åªæ˜¾ç¤ºå½“å‰è¿›åº¦ï¼Œä¸ç¿»è¯‘
  --help       æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  python translate_all.py           # ä¸²è¡Œç¿»è¯‘
  python translate_all.py -p 4      # 4 çº¿ç¨‹å¹¶è¡Œç¿»è¯‘
  python translate_all.py --reset   # ä»å¤´å¼€å§‹
  python translate_all.py --status  # æŸ¥çœ‹è¿›åº¦

å¹¶è¡Œæ¨¡å¼è¯´æ˜:
  - æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„ API Key
  - çº¿ç¨‹ 1: gameevents
  - çº¿ç¨‹ 2: luaapi/classes + functions
  - çº¿ç¨‹ 3: luaapi/enums + constants
  - çº¿ç¨‹ 4: panoramaapi + panoramaevents
""")


def show_status():
    """åªæ˜¾ç¤ºè¿›åº¦çŠ¶æ€"""
    progress = load_progress()
    failed = load_failed()
    
    print("\nğŸ“‹ ç¿»è¯‘è¿›åº¦:")
    print("-" * 60)
    
    total_items = 0
    completed_items = 0
    total_failed = 0
    
    for task in TRANSLATE_TASKS:
        source_path = DATA_DIR / task["source"]
        if source_path.exists():
            with open(source_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            count = len(data.get(task["item_key"], []))
            done = progress.get(task["source"], 0)
            failed_count = len(failed.get(task["source"], []))
            total_items += count
            completed_items += done
            total_failed += failed_count
            
            pct = done * 100 // count if count > 0 else 0
            bar = "â–ˆ" * (pct // 5) + "â–‘" * (20 - pct // 5)
            status = "âœ…" if done >= count else "â³"
            failed_str = f" âŒ{failed_count}" if failed_count > 0 else ""
            
            print(f"{status} {task['source']}")
            print(f"   [{bar}] {done}/{count} ({pct}%){failed_str}")
    
    print("-" * 60)
    total_pct = completed_items * 100 // total_items if total_items > 0 else 0
    print(f"ğŸ“Š æ€»è¿›åº¦: {completed_items}/{total_items} ({total_pct}%)")
    if total_failed > 0:
        print(f"âš ï¸  å¾…é‡è¯•: {total_failed} æ¡")
    print()


if __name__ == "__main__":
    import sys
    
    if "--help" in sys.argv or "-h" in sys.argv:
        print_help()
    elif "--reset" in sys.argv:
        confirm = input("âš ï¸ ç¡®å®šè¦é‡ç½®æ‰€æœ‰è¿›åº¦å—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰ç¿»è¯‘ç»“æœï¼(è¾“å…¥ yes ç¡®è®¤): ")
        if confirm.lower() == "yes":
            reset_progress()
        else:
            print("å·²å–æ¶ˆ")
    elif "--status" in sys.argv:
        show_status()
    elif "-p" in sys.argv:
        # å¹¶è¡Œæ¨¡å¼
        try:
            idx = sys.argv.index("-p")
            parallel = int(sys.argv[idx + 1])
            parallel = max(1, min(parallel, 4))  # é™åˆ¶ 1-4
            main(parallel=parallel)
        except (IndexError, ValueError):
            print("é”™è¯¯: -p åé¢éœ€è¦æŒ‡å®šçº¿ç¨‹æ•°ï¼Œå¦‚ -p 4")
            print_help()
    else:
        main(parallel=1)
